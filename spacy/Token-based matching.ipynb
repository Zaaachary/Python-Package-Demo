{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token-based matching\n",
    "\n",
    "spaCy features a **rule-matching engine**, the `Matcher`, that operates over tokens, similar to regular expressions. \n",
    "The rules can refer to **token annotations** (e.g. the token text or tag_, and flags (e.g. IS_PUNCT). \n",
    "The rule matcher also lets you pass in a custom callback to act on matches – for example, to merge entities and apply custom labels. \n",
    "You can also associate patterns with entity IDs, to allow some basic entity linking or disambiguation. To match large terminology lists, you can use the PhraseMatcher, which accepts Doc objects as match patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增加 patterns\n",
    "1. A token whose lowercase form matches “hello”, e.g. “Hello” or “HELLO”.\n",
    "2. A token whose is_punct flag is set to True, i.e. any punctuation.\n",
    "3. A token whose lowercase form matches “world”, e.g. “World” or “WORLD”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the `Matcher` with a **vocab**. The matcher must always share the same vocab with the documents it will operate on.\n",
    "\n",
    "We can now call `matcher.add()` with an `ID` and our `custom pattern`. \n",
    "\n",
    "The second argument lets you pass in an optional callback function to invoke on a successful match. For now, we set it to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n",
    "\n",
    "matcher.add(\"HelloWorld\", None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15578876784678163569 HelloWorld 0 3 Hello, world\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hello, world! Hello world!\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://spacy.io/usage/rule-based-matching#matcher"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "package_demo",
   "language": "python",
   "name": "package_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
